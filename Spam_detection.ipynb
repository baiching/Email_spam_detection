{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef87146-51fc-4c6a-b1eb-04b8dc84d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2ee7ea3-1989-4664-b1f2-0364f5be3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"./data/email_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581b47fd-d8cb-4693-a6ce-afc49620182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179 entries, 0 to 178\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   179 non-null    object\n",
      " 1   label   179 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.describe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843482fd-03cc-49ab-bc7b-366d8d7dbe31",
   "metadata": {},
   "source": [
    "## Cleaning the data and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10bd08ad-d480-4a9a-9390-2d7c20aaeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['email'] = df['email'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35086d99-a440-44fa-97cd-f7606696ce60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrade to our premium plan for exclusive acce...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy holidays from our team! wishing you joy ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we're hiring! check out our career opportuniti...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your amazon account has been locked. click her...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your opinion matters! take our survey and help...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>we're pleased to inform you that your refund h...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>get rich quick! invest in our revolutionary ne...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>your free trial period is ending soon. upgrade...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>your order is on its way! track your shipment ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>limited-time offer! get 50% off on all purchas...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 email label\n",
       "0    upgrade to our premium plan for exclusive acce...   ham\n",
       "1    happy holidays from our team! wishing you joy ...   ham\n",
       "2    we're hiring! check out our career opportuniti...   ham\n",
       "3    your amazon account has been locked. click her...  spam\n",
       "4    your opinion matters! take our survey and help...   ham\n",
       "..                                                 ...   ...\n",
       "174  we're pleased to inform you that your refund h...   ham\n",
       "175  get rich quick! invest in our revolutionary ne...  spam\n",
       "176  your free trial period is ending soon. upgrade...   ham\n",
       "177  your order is on its way! track your shipment ...   ham\n",
       "178  limited-time offer! get 50% off on all purchas...  spam\n",
       "\n",
       "[179 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2128db26-d352-4179-81a4-c4ba21fdb242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bachm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e94efdb6-844a-4468-af6c-405c0cda6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['email'] = df['email'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40fbe1c2-3dca-4f58-bead-a4e01d9a1361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [upgrade, to, our, premium, plan, for, exclusi...\n",
       "1      [happy, holidays, from, our, team, !, wishing,...\n",
       "2      [we, 're, hiring, !, check, out, our, career, ...\n",
       "3      [your, amazon, account, has, been, locked, ., ...\n",
       "4      [your, opinion, matters, !, take, our, survey,...\n",
       "                             ...                        \n",
       "174    [we, 're, pleased, to, inform, you, that, your...\n",
       "175    [get, rich, quick, !, invest, in, our, revolut...\n",
       "176    [your, free, trial, period, is, ending, soon, ...\n",
       "177    [your, order, is, on, its, way, !, track, your...\n",
       "178    [limited-time, offer, !, get, 50, %, off, on, ...\n",
       "Name: email, Length: 179, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['email']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08575839-caa2-46b8-bfcb-ae6291f97f39",
   "metadata": {},
   "source": [
    "## Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7565a529-44a8-4c88-b54f-dbbcaac19d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_stop_words(sentence):\n",
    "    stop_words  = [\"the\", \"and\", \"a\", \"to\", \"of\", \"in\", \"is\", \"you\", \"for\", \"on\",\n",
    "    \"with\", \"that\", \"as\", \"it\", \"be\", \"are\", \"this\", \"from\", \"or\", \"by\",\n",
    "    \"your\", \"at\", \"not\", \"have\", \"was\", \"but\", \"which\", \"an\", \"if\", \"they\"]\n",
    "    #word_list=sentence.split()\n",
    "    clean_sentence=' '.join([w for w in sentence if w.lower() not in stop_words])\n",
    "    return(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48a9d384-7d58-4bd0-826c-317429d7015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['email'] = df['email'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7fe6c75-3d15-4f19-b5fc-9c15a18ec3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [upgrade, our, premium, plan, exclusive, acces...\n",
       "1      [happy, holidays, our, team, !, wishing, joy, ...\n",
       "2      [we, 're, hiring, !, check, out, our, career, ...\n",
       "3      [amazon, account, has, been, locked, ., click,...\n",
       "4      [opinion, matters, !, take, our, survey, help,...\n",
       "                             ...                        \n",
       "174    [we, 're, pleased, inform, refund, has, been, ...\n",
       "175    [get, rich, quick, !, invest, our, revolutiona...\n",
       "176    [free, trial, period, ending, soon, ., upgrade...\n",
       "177    [order, its, way, !, track, shipment, real-tim...\n",
       "178    [limited-time, offer, !, get, 50, %, off, all,...\n",
       "Name: email, Length: 179, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['email'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed2714b0-dac6-4775-9d6d-a2a8ad13ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=df['email'], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2076d0ac-7637-4ac9-97cd-df802dd3ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"emailWord2Vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1698074c-39bf-4ae9-b74d-439f314b3e2d",
   "metadata": {},
   "source": [
    "## Converting to text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4d3dc11-9f27-49ef-8d96-45011accf1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1be2a944080>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the model\n",
    "model = Word2Vec.load(\"emailWord2Vec.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6385085-07b9-4ae1-a0d3-fff6ec00ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 179 entries, 0 to 178\n",
      "Series name: label\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "179 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df['label'].value_counts()\n",
    "\n",
    "pd.get_dummies(df['label'], prefix='label')\n",
    "\n",
    "df['label'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35d315e9-113a-4dfe-90de-2ce091fd375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "#enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc = LabelEncoder()\n",
    "\n",
    "x = enc.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c6733ac-e18b-4a90-b627-fa8034356693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mm = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19747e19-a834-4851-9c58-1964c6ac8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for document in df['label']:\n",
    "    # Filter out words not in the model's vocabulary\n",
    "    vectors = [model.wv[word] for word in document if word in model.wv]\n",
    "    if vectors:  # check if there are any vectors\n",
    "        mean_vector = np.mean(vectors, axis=0)\n",
    "        X.append(mean_vector)\n",
    "    else:\n",
    "        # Handle documents that may not have any words in the model's vocabulary\n",
    "        # For instance, by appending a zero vector of the same length as others\n",
    "        X.append(np.zeros(model.vector_size))\n",
    "\n",
    "# Convert the list of vectors into an array for machine learning usage\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d41af313-a78d-420c-b3e6-247ddf5be245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08787648,  0.2448949 ,  0.10689574, ..., -0.09616518,\n",
       "         0.02436404,  0.16101478],\n",
       "       [-0.08787648,  0.2448949 ,  0.10689574, ..., -0.09616518,\n",
       "         0.02436404,  0.16101478],\n",
       "       [-0.08787648,  0.2448949 ,  0.10689574, ..., -0.09616518,\n",
       "         0.02436404,  0.16101478],\n",
       "       ...,\n",
       "       [-0.08787648,  0.2448949 ,  0.10689574, ..., -0.09616518,\n",
       "         0.02436404,  0.16101478],\n",
       "       [-0.08787648,  0.2448949 ,  0.10689574, ..., -0.09616518,\n",
       "         0.02436404,  0.16101478],\n",
       "       [-0.08796126,  0.2495893 ,  0.11155474, ..., -0.09393063,\n",
       "         0.02863941,  0.16644704]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6c68920-45b0-4844-875b-0a6da8a33ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, x, test_size=0.2, random_state=42)\n",
    "randf = RandomForestClassifier()\n",
    "svc_clas = SVC()\n",
    "\n",
    "mm.fit(X_train, y_train)\n",
    "randf.fit(X_train, y_train)\n",
    "svc_clas.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_gaus = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25427081-198a-4066-bacf-1b5e5df60733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regregression Accuracy: 0.3888888888888889\n",
      "Random Forrest Accuracy: 1.0\n",
      "SVM Accuracy: 0.3888888888888889\n",
      "Naive Bayes Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56        14\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.39        36\n",
      "   macro avg       0.19      0.50      0.28        36\n",
      "weighted avg       0.15      0.39      0.22        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\models\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\models\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\models\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = mm.predict(X_test)\n",
    "y_pred_rand = randf.predict(X_test)\n",
    "y_pred_svc = svc_clas.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Logistic Regregression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Random Forrest Accuracy:\", accuracy_score(y_test, y_pred_rand))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_gaus))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffad33-1e11-49ae-aee5-96bba82b4f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
